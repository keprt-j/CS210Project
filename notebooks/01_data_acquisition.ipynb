{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TB Data Acquisition\n",
    "\n",
    "Fetch and load TB data from WHO GHO API (2018-2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project: /Users/joshua/datascienceproject\n",
      "✓ Database: /Users/joshua/datascienceproject/data/database/tb_data.db\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) \n",
    "                     if (p / 'notebooks' / '01_data_acquisition.ipynb').exists()),\n",
    "                    Path.cwd())\n",
    "os.chdir(project_root)\n",
    "\n",
    "# API Configuration\n",
    "WHO_GHO_API_BASE = \"https://ghoapi.azureedge.net/api\"\n",
    "WHO_INDICATORS = {\n",
    "    \"tb_incidence\": \"TB_e_inc_tbhiv_num\",\n",
    "    \"tb_mortality\": \"TB_e_mort_exc_tbhiv_num\",\n",
    "}\n",
    "\n",
    "# Data parameters\n",
    "START_YEAR = 2018\n",
    "END_YEAR = 2023\n",
    "YEARS = list(range(START_YEAR, END_YEAR + 1))\n",
    "\n",
    "# Paths\n",
    "DATABASE_PATH = str(project_root / \"data\" / \"database\" / \"tb_data.db\")\n",
    "RAW_DATA_DIR = project_root / \"data\" / \"raw\"\n",
    "\n",
    "print(f\"✓ Project: {project_root}\")\n",
    "print(f\"✓ Database: {DATABASE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_db_connection(db_path):\n",
    "    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn\n",
    "\n",
    "def create_schema(db_path):\n",
    "    conn = get_db_connection(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS country_metadata (\n",
    "            country_code TEXT PRIMARY KEY,\n",
    "            region_code TEXT,\n",
    "            region_name TEXT,\n",
    "            UNIQUE(country_code)\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS tb_data (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            country_code TEXT NOT NULL,\n",
    "            year INTEGER NOT NULL,\n",
    "            tb_incidence_num REAL,\n",
    "            tb_incidence_low REAL,\n",
    "            tb_incidence_high REAL,\n",
    "            tb_mortality_num REAL,\n",
    "            tb_mortality_low REAL,\n",
    "            tb_mortality_high REAL,\n",
    "            tb_incidence_rate REAL,\n",
    "            FOREIGN KEY (country_code) REFERENCES country_metadata(country_code),\n",
    "            UNIQUE(country_code, year)\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_tb_country_year ON tb_data(country_code, year)\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Database schema created successfully at {db_path}\")\n",
    "\n",
    "def create_unified_view(db_path: str):\n",
    "    conn = get_db_connection(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"DROP VIEW IF EXISTS unified_tb_data\")\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE VIEW unified_tb_data AS\n",
    "        SELECT \n",
    "            cm.country_code, cm.region_code, cm.region_name,\n",
    "            tb.year, tb.tb_incidence_num, tb.tb_incidence_low, tb.tb_incidence_high,\n",
    "            tb.tb_mortality_num, tb.tb_mortality_low, tb.tb_mortality_high, tb.tb_incidence_rate\n",
    "        FROM country_metadata cm\n",
    "        LEFT JOIN tb_data tb ON cm.country_code = tb.country_code\n",
    "        ORDER BY cm.country_code, tb.year\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Unified view created successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Fetching Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API fetching functions\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch(indicator: str, years=None):\n",
    "    if years is None:\n",
    "        years = YEARS\n",
    "        \n",
    "    url = f\"{WHO_GHO_API_BASE}/{indicator}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'value' not in data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(data['value'])\n",
    "        if df.empty:\n",
    "            return df\n",
    "        \n",
    "        if years:\n",
    "            df = df[df['TimeDim'].isin(years)].copy()\n",
    "        \n",
    "        df.rename(columns={\n",
    "            'SpatialDim': 'country_code', 'TimeDim': 'year', 'NumericValue': 'value',\n",
    "            'Low': 'value_low', 'High': 'value_high',\n",
    "            'ParentLocation': 'region_name', 'ParentLocationCode': 'region_code'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        df = df[df.get('SpatialDimType', '') == 'COUNTRY'].copy()\n",
    "        df = df.dropna(subset=['country_code', 'year'])\n",
    "        df = df[df['value'] > 0].copy()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {indicator}: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Loading Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database loading functions\n",
    "def _update_metadata(conn, df):\n",
    "    if 'region_code' not in df.columns or 'region_name' not in df.columns:\n",
    "        return\n",
    "    metadata = df[['country_code', 'region_code', 'region_name']].drop_duplicates()\n",
    "    for _, row in metadata.iterrows():\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT OR REPLACE INTO country_metadata (country_code, region_code, region_name)\n",
    "            VALUES (?, ?, ?)\n",
    "        \"\"\", (row['country_code'], row.get('region_code'), row.get('region_name')))\n",
    "\n",
    "def _upsert_tb_data(conn, df, field):\n",
    "    \"\"\"Upsert TB data (incidence or mortality).\"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT id FROM tb_data WHERE country_code = ? AND year = ?\",\n",
    "                      (row['country_code'], int(row['year'])))\n",
    "        if cursor.fetchone():\n",
    "            conn.execute(f\"\"\"\n",
    "                UPDATE tb_data SET {field}_num = ?, {field}_low = ?, {field}_high = ?\n",
    "                WHERE country_code = ? AND year = ?\n",
    "            \"\"\", (row.get('value'), row.get('value_low'), row.get('value_high'),\n",
    "                  row['country_code'], int(row['year'])))\n",
    "        else:\n",
    "            conn.execute(f\"\"\"\n",
    "                INSERT INTO tb_data (country_code, year, {field}_num, {field}_low, {field}_high)\n",
    "                VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\", (row['country_code'], int(row['year']), row.get('value'),\n",
    "                  row.get('value_low'), row.get('value_high')))\n",
    "\n",
    "def load_tb_incidence(df, db_path):\n",
    "    if df.empty:\n",
    "        return\n",
    "    conn = get_db_connection(db_path)\n",
    "    _update_metadata(conn, df)\n",
    "    _upsert_tb_data(conn, df, 'tb_incidence')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Loaded {len(df)} TB incidence records\")\n",
    "\n",
    "def load_tb_mortality(df, db_path):\n",
    "    if df.empty:\n",
    "        return\n",
    "    conn = get_db_connection(db_path)\n",
    "    _update_metadata(conn, df)\n",
    "    _upsert_tb_data(conn, df, 'tb_mortality')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Loaded {len(df)} TB mortality records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition Orchestration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main orchestration functions\n",
    "def save_csv(df, filename):\n",
    "    \"\"\"Save DataFrame to CSV.\"\"\"\n",
    "    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(RAW_DATA_DIR / filename, index=False)\n",
    "\n",
    "def acquire_all():\n",
    "    datasets = {}\n",
    "    \n",
    "    # WHO data\n",
    "    for key, indicator in [('tb_incidence', WHO_INDICATORS['tb_incidence']),\n",
    "                          ('tb_mortality', WHO_INDICATORS['tb_mortality'])]:\n",
    "        df = fetch(indicator, YEARS)\n",
    "        if not df.empty:\n",
    "            datasets[key] = df\n",
    "            save_csv(df, f'{key}.csv')\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "def load_all(datasets, db_path):\n",
    "    \"\"\"Load all datasets into database.\"\"\"\n",
    "    loaders = {\n",
    "        'tb_incidence': load_tb_incidence,\n",
    "        'tb_mortality': load_tb_mortality\n",
    "    }\n",
    "    \n",
    "    for key, loader in loaders.items():\n",
    "        if key in datasets:\n",
    "            loader(datasets[key], db_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Create Database Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database schema created successfully at /Users/joshua/datascienceproject/data/database/tb_data.db\n"
     ]
    }
   ],
   "source": [
    "# Create database schema\n",
    "create_schema(DATABASE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Fetch Data from APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 2 datasets\n"
     ]
    }
   ],
   "source": [
    "# Fetch all data from APIs\n",
    "datasets = acquire_all()\n",
    "print(f\"Fetched {len(datasets)} datasets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Load Data into Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1002 TB incidence records\n",
      "Loaded 1062 TB mortality records\n",
      "Unified view created successfully\n",
      "Data acquisition complete\n"
     ]
    }
   ],
   "source": [
    "# Load into database\n",
    "load_all(datasets, DATABASE_PATH)\n",
    "create_unified_view(DATABASE_PATH)\n",
    "print(\"Data acquisition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Verify Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Coverage by Year:\n",
      "     country_code region_code      region_name  year  tb_incidence_num  \\\n",
      "0             ZWE         AFR           Africa  2018           20000.0   \n",
      "1             SGP         WPR  Western Pacific  2018              35.0   \n",
      "2             JAM         AMR         Americas  2018              17.0   \n",
      "3             UZB         EUR           Europe  2018            1000.0   \n",
      "4             MUS         AFR           Africa  2018              44.0   \n",
      "...           ...         ...              ...   ...               ...   \n",
      "1057          TLS        SEAR  South-East Asia  2023              57.0   \n",
      "1058          MWI         AFR           Africa  2023           12000.0   \n",
      "1059          ECU         AMR         Americas  2023            1500.0   \n",
      "1060          IDN         WPR  Western Pacific  2023           25000.0   \n",
      "1061          AUS         WPR  Western Pacific  2023              30.0   \n",
      "\n",
      "      tb_incidence_low  tb_incidence_high  tb_mortality_num  tb_mortality_low  \\\n",
      "0              13000.0            27000.0            1200.0             720.0   \n",
      "1                 22.0               51.0              34.0              30.0   \n",
      "2                  9.0               28.0               7.0               7.0   \n",
      "3                750.0             1300.0            1400.0            1300.0   \n",
      "4                 28.0               63.0              17.0              16.0   \n",
      "...                ...                ...               ...               ...   \n",
      "1057              42.0               75.0             290.0             120.0   \n",
      "1058            5200.0            21000.0            1700.0             800.0   \n",
      "1059            1100.0             2000.0             540.0             460.0   \n",
      "1060           11000.0            45000.0          125000.0          109000.0   \n",
      "1061              18.0               45.0              36.0              35.0   \n",
      "\n",
      "      tb_mortality_high tb_incidence_rate  \n",
      "0                1700.0              None  \n",
      "1                  38.0              None  \n",
      "2                   7.0              None  \n",
      "3                1600.0              None  \n",
      "4                  17.0              None  \n",
      "...                 ...               ...  \n",
      "1057              540.0              None  \n",
      "1058             3000.0              None  \n",
      "1059              630.0              None  \n",
      "1060           142000.0              None  \n",
      "1061               36.0              None  \n",
      "\n",
      "[1062 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verify data\n",
    "import pandas as pd\n",
    "\n",
    "conn = get_db_connection(DATABASE_PATH)\n",
    "summary = pd.read_sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM unified_tb_data\n",
    "    ORDER BY year\n",
    "\"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(\"Data Coverage by Year:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
